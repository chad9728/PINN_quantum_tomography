{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 消融实验：PINN架构组件贡献分析\n",
        "\n",
        "本Notebook系统评估PINN架构中各组件的贡献，包括：\n",
        "1. Residual Connections的影响\n",
        "2. Attention Mechanism的影响\n",
        "3. Dynamic Weighting vs Fixed Weighting\n",
        "4. 不同约束权重设置的影响\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "消融实验环境已就绪！\n",
            "消融实验环境已就绪！\n",
            "Cholesky参数维度验证: 对于3-qubit系统(dim=8), output_dim应该是64, 实际=64\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import importlib\n",
        "sys.path.append('.')\n",
        "\n",
        "# 重新加载模块以确保使用最新代码\n",
        "if 'ablation_study' in sys.modules:\n",
        "    importlib.reload(sys.modules['ablation_study'])\n",
        "from ablation_study import *\n",
        "\n",
        "print(\"消融实验环境已就绪！\")\n",
        "print(f\"Cholesky参数维度验证: 对于3-qubit系统(dim=8), output_dim应该是64, 实际={8*8}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "对于3-qubit系统 (dim=8):\n",
            "  对角元素参数: 8\n",
            "  非对角元素参数: 56\n",
            "  总参数数量: 64\n",
            "  dim*dim = 64\n",
            "  验证: total_params == dim*dim? True\n",
            "\n",
            "模型output_dim: 64\n",
            "预期output_dim: 64\n",
            "维度匹配: True\n"
          ]
        }
      ],
      "source": [
        "# 验证维度计算\n",
        "n_qubits = 3\n",
        "dim = 2 ** n_qubits\n",
        "# 对角元素：dim个，每个1个参数\n",
        "diag_params = dim\n",
        "# 非对角元素：dim*(dim-1)/2个，每个2个参数（实部+虚部）\n",
        "off_diag_params = dim * (dim - 1) // 2 * 2\n",
        "total_params = diag_params + off_diag_params\n",
        "\n",
        "print(f\"对于{n_qubits}-qubit系统 (dim={dim}):\")\n",
        "print(f\"  对角元素参数: {diag_params}\")\n",
        "print(f\"  非对角元素参数: {off_diag_params}\")\n",
        "print(f\"  总参数数量: {total_params}\")\n",
        "print(f\"  dim*dim = {dim*dim}\")\n",
        "print(f\"  验证: total_params == dim*dim? {total_params == dim*dim}\")\n",
        "\n",
        "# 测试模型初始化\n",
        "test_model = AblationPINN(n_qubits=3, input_dim=64, hidden_dims=[256, 128])\n",
        "print(f\"\\n模型output_dim: {test_model.output_dim}\")\n",
        "print(f\"预期output_dim: {dim*dim}\")\n",
        "print(f\"维度匹配: {test_model.output_dim == dim*dim}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 运行消融实验\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用设备: cpu\n",
            "\n",
            "============================================================\n",
            "开始消融实验 - 3 qubits\n",
            "============================================================\n",
            "\n",
            "生成数据集...\n",
            "\n",
            "训练配置: Full Model\n",
            "------------------------------------------------------------\n",
            "Epoch 5/25 - Train Loss: 0.004572, Val Loss: 0.004607, Fidelity: 0.7653, CV: 3.32e-33\n",
            "Epoch 10/25 - Train Loss: 0.002949, Val Loss: 0.004259, Fidelity: 0.7978, CV: 3.76e-33\n",
            "Epoch 15/25 - Train Loss: 0.002075, Val Loss: 0.004095, Fidelity: 0.8100, CV: 3.90e-33\n",
            "Epoch 20/25 - Train Loss: 0.001656, Val Loss: 0.004018, Fidelity: 0.8152, CV: 3.73e-33\n",
            "Epoch 25/25 - Train Loss: 0.001556, Val Loss: 0.004013, Fidelity: 0.8158, CV: 3.61e-33\n",
            "最佳保真度: 0.8158\n",
            "\n",
            "训练配置: w/o Residual\n",
            "------------------------------------------------------------\n",
            "Epoch 5/25 - Train Loss: 0.004621, Val Loss: 0.004662, Fidelity: 0.7584, CV: 3.29e-33\n",
            "Epoch 10/25 - Train Loss: 0.003157, Val Loss: 0.004239, Fidelity: 0.7917, CV: 3.58e-33\n",
            "Epoch 15/25 - Train Loss: 0.002413, Val Loss: 0.004094, Fidelity: 0.8052, CV: 3.70e-33\n",
            "Epoch 20/25 - Train Loss: 0.002055, Val Loss: 0.004049, Fidelity: 0.8100, CV: 3.85e-33\n",
            "Epoch 25/25 - Train Loss: 0.002011, Val Loss: 0.004022, Fidelity: 0.8110, CV: 3.29e-33\n",
            "最佳保真度: 0.8115\n",
            "\n",
            "训练配置: w/o Attention\n",
            "------------------------------------------------------------\n",
            "Epoch 5/25 - Train Loss: 0.005413, Val Loss: 0.005148, Fidelity: 0.7267, CV: 3.50e-33\n",
            "Epoch 10/25 - Train Loss: 0.004044, Val Loss: 0.004698, Fidelity: 0.7629, CV: 3.39e-33\n",
            "Epoch 15/25 - Train Loss: 0.003102, Val Loss: 0.004447, Fidelity: 0.7814, CV: 3.44e-33\n",
            "Epoch 20/25 - Train Loss: 0.002619, Val Loss: 0.004373, Fidelity: 0.7893, CV: 3.92e-33\n",
            "Epoch 25/25 - Train Loss: 0.002419, Val Loss: 0.004367, Fidelity: 0.7902, CV: 3.56e-33\n",
            "最佳保真度: 0.7906\n",
            "\n",
            "训练配置: Fixed Weight (0.15)\n",
            "------------------------------------------------------------\n",
            "Epoch 5/25 - Train Loss: 0.004590, Val Loss: 0.004636, Fidelity: 0.7615, CV: 3.48e-33\n",
            "Epoch 10/25 - Train Loss: 0.003014, Val Loss: 0.004238, Fidelity: 0.7956, CV: 3.74e-33\n",
            "Epoch 15/25 - Train Loss: 0.002089, Val Loss: 0.004044, Fidelity: 0.8093, CV: 3.83e-33\n",
            "Epoch 20/25 - Train Loss: 0.001705, Val Loss: 0.004009, Fidelity: 0.8124, CV: 4.06e-33\n",
            "Epoch 25/25 - Train Loss: 0.001563, Val Loss: 0.003974, Fidelity: 0.8140, CV: 3.66e-33\n",
            "最佳保真度: 0.8140\n",
            "\n",
            "训练配置: Fixed Weight (0.05)\n",
            "------------------------------------------------------------\n",
            "Epoch 5/25 - Train Loss: 0.004460, Val Loss: 0.004714, Fidelity: 0.7590, CV: 3.26e-33\n",
            "Epoch 10/25 - Train Loss: 0.002948, Val Loss: 0.004298, Fidelity: 0.7936, CV: 3.72e-33\n",
            "Epoch 15/25 - Train Loss: 0.002074, Val Loss: 0.004053, Fidelity: 0.8092, CV: 4.27e-33\n",
            "Epoch 20/25 - Train Loss: 0.001662, Val Loss: 0.003999, Fidelity: 0.8126, CV: 3.70e-33\n",
            "Epoch 25/25 - Train Loss: 0.001564, Val Loss: 0.003978, Fidelity: 0.8139, CV: 3.65e-33\n",
            "最佳保真度: 0.8139\n",
            "\n",
            "训练配置: Fixed Weight (0.30)\n",
            "------------------------------------------------------------\n",
            "Epoch 5/25 - Train Loss: 0.004545, Val Loss: 0.004688, Fidelity: 0.7556, CV: 3.65e-33\n",
            "Epoch 10/25 - Train Loss: 0.002924, Val Loss: 0.004405, Fidelity: 0.7906, CV: 3.59e-33\n",
            "Epoch 15/25 - Train Loss: 0.002097, Val Loss: 0.004247, Fidelity: 0.8005, CV: 3.69e-33\n",
            "Epoch 20/25 - Train Loss: 0.001666, Val Loss: 0.004141, Fidelity: 0.8060, CV: 3.45e-33\n",
            "Epoch 25/25 - Train Loss: 0.001559, Val Loss: 0.004113, Fidelity: 0.8086, CV: 3.90e-33\n",
            "最佳保真度: 0.8086\n",
            "\n",
            "训练配置: Baseline (w/o all)\n",
            "------------------------------------------------------------\n",
            "Epoch 5/25 - Train Loss: 0.005348, Val Loss: 0.005131, Fidelity: 0.7325, CV: 3.50e-33\n",
            "Epoch 10/25 - Train Loss: 0.003753, Val Loss: 0.004487, Fidelity: 0.7757, CV: 3.68e-33\n",
            "Epoch 15/25 - Train Loss: 0.003039, Val Loss: 0.004268, Fidelity: 0.7900, CV: 3.53e-33\n",
            "Epoch 20/25 - Train Loss: 0.002565, Val Loss: 0.004202, Fidelity: 0.7960, CV: 3.63e-33\n",
            "Epoch 25/25 - Train Loss: 0.002490, Val Loss: 0.004211, Fidelity: 0.7967, CV: 4.16e-33\n",
            "最佳保真度: 0.7974\n"
          ]
        }
      ],
      "source": [
        "# 运行消融实验\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"使用设备: {device}\")\n",
        "\n",
        "results = run_ablation_study(\n",
        "    n_qubits=3, \n",
        "    n_train=3000, \n",
        "    n_val=800, \n",
        "    epochs=25, \n",
        "    device=device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 生成可视化图表\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "结果已保存到: ./ablation_results\n",
            "\n",
            "结果摘要:\n",
            "      Configuration Best Fidelity Final Fidelity Final Constraint Violation\n",
            "         Full Model        0.8158         0.8158                   3.61e-33\n",
            "       w/o Residual        0.8115         0.8110                   3.29e-33\n",
            "      w/o Attention        0.7906         0.7902                   3.56e-33\n",
            "Fixed Weight (0.15)        0.8140         0.8140                   3.66e-33\n",
            "Fixed Weight (0.05)        0.8139         0.8139                   3.65e-33\n",
            "Fixed Weight (0.30)        0.8086         0.8086                   3.90e-33\n",
            " Baseline (w/o all)        0.7974         0.7967                   4.16e-33\n"
          ]
        }
      ],
      "source": [
        "# 绘制所有结果\n",
        "plot_ablation_results(results, save_dir='./ablation_results')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 生成论文专用图表\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "论文专用图表已生成！\n"
          ]
        }
      ],
      "source": [
        "# 生成论文中需要的消融研究结果图\n",
        "def create_paper_figures(results, save_dir='./ablation_results'):\n",
        "    \"\"\"创建论文中使用的图表\"\"\"\n",
        "    \n",
        "    # 1. 保真度对比柱状图（论文用）\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    configs = [r['config'] for r in results]\n",
        "    fidelities = [r['best_fidelity'] for r in results]\n",
        "    \n",
        "    # 使用更专业的配色\n",
        "    colors = ['#2E86AB' if 'Full' in c else '#A23B72' if 'Baseline' in c else '#F18F01' \n",
        "              for c in configs]\n",
        "    \n",
        "    bars = ax.bar(configs, fidelities, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "    ax.set_ylabel('Fidelity', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Model Configuration', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Ablation Study: Component Contribution to Reconstruction Fidelity', \n",
        "                 fontsize=16, fontweight='bold')\n",
        "    ax.set_ylim([min(fidelities) * 0.95, max(fidelities) * 1.02])\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # 添加数值标签\n",
        "    for bar, fid in zip(bars, fidelities):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{fid:.4f}',\n",
        "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{save_dir}/ablation_fidelity_paper.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(f'{save_dir}/ablation_fidelity_paper.pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    # 2. 组件贡献分解图\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    baseline_fid = next(r['best_fidelity'] for r in results if 'Baseline' in r['config'])\n",
        "    \n",
        "    # 计算每个组件的贡献\n",
        "    components = []\n",
        "    contributions = []\n",
        "    \n",
        "    # Residual贡献\n",
        "    no_residual = next((r['best_fidelity'] for r in results if 'w/o Residual' in r['config']), baseline_fid)\n",
        "    residual_contrib = (next(r['best_fidelity'] for r in results if 'Full' in r['config']) - no_residual) / baseline_fid * 100\n",
        "    components.append('Residual\\\\nConnections')\n",
        "    contributions.append(residual_contrib)\n",
        "    \n",
        "    # Attention贡献\n",
        "    no_attention = next((r['best_fidelity'] for r in results if 'w/o Attention' in r['config']), baseline_fid)\n",
        "    attention_contrib = (next(r['best_fidelity'] for r in results if 'Full' in r['config']) - no_attention) / baseline_fid * 100\n",
        "    components.append('Attention\\\\nMechanism')\n",
        "    contributions.append(attention_contrib)\n",
        "    \n",
        "    # Dynamic Weighting贡献\n",
        "    fixed_weight = next((r['best_fidelity'] for r in results if 'Fixed Weight (0.15)' in r['config']), baseline_fid)\n",
        "    dynamic_contrib = (next(r['best_fidelity'] for r in results if 'Full' in r['config']) - fixed_weight) / baseline_fid * 100\n",
        "    components.append('Dynamic\\\\nWeighting')\n",
        "    contributions.append(dynamic_contrib)\n",
        "    \n",
        "    bars = ax.bar(components, contributions, color=['#2E86AB', '#A23B72', '#F18F01'], \n",
        "                 alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "    ax.set_ylabel('Improvement over Baseline (%)', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Component', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Individual Component Contribution to Performance', \n",
        "                 fontsize=16, fontweight='bold')\n",
        "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # 添加数值标签\n",
        "    for bar, contrib in zip(bars, contributions):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{contrib:+.2f}%',\n",
        "                ha='center', va='bottom' if contrib > 0 else 'top', \n",
        "                fontsize=11, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{save_dir}/ablation_component_contribution_paper.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(f'{save_dir}/ablation_component_contribution_paper.pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "    \n",
        "    print(\"论文专用图表已生成！\")\n",
        "\n",
        "create_paper_figures(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 详细结果分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Configuration Best Fidelity Final Fidelity Final CV Improvement over Baseline (%)\n",
            "         Full Model        0.8158         0.8158 3.61e-33                          2.30\n",
            "       w/o Residual        0.8115         0.8110 3.29e-33                          1.77\n",
            "      w/o Attention        0.7906         0.7902 3.56e-33                         -0.86\n",
            "Fixed Weight (0.15)        0.8140         0.8140 3.66e-33                          2.09\n",
            "Fixed Weight (0.05)        0.8139         0.8139 3.65e-33                          2.07\n",
            "Fixed Weight (0.30)        0.8086         0.8086 3.90e-33                          1.41\n",
            " Baseline (w/o all)        0.7974         0.7967 4.16e-33                          0.00\n"
          ]
        }
      ],
      "source": [
        "# 显示结果表格\n",
        "import pandas as pd\n",
        "baseline_fid = next(r['best_fidelity'] for r in results if 'Baseline' in r['config'])\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "        'Configuration': r['config'],\n",
        "        'Best Fidelity': f\"{r['best_fidelity']:.4f}\",\n",
        "        'Final Fidelity': f\"{r['final_fidelity']:.4f}\",\n",
        "        'Final CV': f\"{r['final_cv']:.2e}\",\n",
        "        'Improvement over Baseline (%)': f\"{((r['best_fidelity'] - baseline_fid) / baseline_fid * 100):.2f}\"\n",
        "    }\n",
        "    for r in results\n",
        "])\n",
        "print(df.to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "d2l",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
